{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpC9PrSeB5H7TRsaTHFvk7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoTorella/progettoLabAI/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "import torch\n",
        "import torchvision\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "import rasterio\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXtgHPPDGniq",
        "outputId": "a01cd18e-c612-41d2-bf9d-48f033abd4a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.10-cp310-cp310-manylinux2014_x86_64.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.10 snuggs-1.4.7\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r drive/MyDrive/progettoLabAi3/train/PS-RGBNIR/test_set /content/images"
      ],
      "metadata": {
        "id": "rBPK6n66kutR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r drive/MyDrive/progettoLabAi3/train/mask/test_set /content/mask"
      ],
      "metadata": {
        "id": "L5tGqw89GrbO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZqtnFBuqFfrk"
      },
      "outputs": [],
      "source": [
        "class MultispectralDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "        string = self.images[index]\n",
        "        mask_name = string.replace('PS-RGBNIR','Buildings').replace(\".tif\",\"_mask.tiff\")\n",
        "        #print(\"STRINGA\"+ string)\n",
        "        #tile_index= indice_numero = max(string.rfind('_'), string.rfind(' '))\n",
        "        #mask_name = string[:tile_index + 1] + \"mask_\" + string[tile_index + 1:]\n",
        "        #print(\"FINALE: \"+ mask_name)\n",
        "        #mask_name = mask_name.replace(\"11 mask_2.tiff\",\"mask_11.tiff\")\n",
        "        #mask_name = mask_name.replace(\"12 mask_2.tiff\",\"mask_12.tiff\")\n",
        "        #mask_name = mask_name.replace(\"13 mask_2.tiff\",\"mask_23.tiff\")\n",
        "        #mask_name = mask_name.replace(\"21 mask_2.tiff\",\"mask_21.tiff\")\n",
        "        #mask_name = mask_name.replace(\"22 mask_2.tiff\",\"mask_22.tiff\")\n",
        "        #mask_name = mask_name.replace(\"23 mask_2.tiff\",\"mask_23.tiff\")\n",
        "        #mask_name = mask_name.replace(\"31 mask_2.tiff\",\"mask_31.tiff\")\n",
        "        #mask_name = mask_name.replace(\"32 mask_2.tiff\",\"mask_32.tiff\")\n",
        "        #mask_name = mask_name.replace(\"33 mask_2.tiff\",\"mask_33.tiff\")\n",
        "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
        "        with rasterio.open(img_path) as src:\n",
        "            image = src.read().transpose((1, 2, 0)).astype(np.float32)\n",
        "        with rasterio.open(mask_path) as src:\n",
        "          mask = src.read().astype(np.float32)\n",
        "\n",
        "        mask[mask == 255.0] = 1.0\n",
        "        mask = mask.squeeze(0)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            augmentations = self.transform(image=image, mask=mask)\n",
        "            image = augmentations[\"image\"]\n",
        "            mask = augmentations[\"mask\"]\n",
        "\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(\n",
        "            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n",
        "    ):\n",
        "        super(UNET, self).__init__()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Down part of UNET\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Up part of UNET\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(\n",
        "                    feature*2, feature, kernel_size=2, stride=2,\n",
        "                )\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[idx//2]\n",
        "\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "        return self.final_conv(x)"
      ],
      "metadata": {
        "id": "1V4o3a9NGu5o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint, model):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "def save_predictions_as_imgs(loader, model, folder=\"/content/drive/My Drive/progettoLabAi3/computations/saved/images/\",\n",
        "                             device=\"cuda\"):\n",
        "    model.eval()  # Imposta il modello in modalità di valutazione\n",
        "    print(f\"Saving images to {folder}\")\n",
        "    iteration = 1\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        print(\"Iteration: \", iteration)\n",
        "        iteration += 1\n",
        "        x = x.to(device=device)\n",
        "        y = y.to(device=device).unsqueeze(1)\n",
        "        with torch.no_grad():\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "\n",
        "        # Concatenare le immagini (maschera originale e predizione) lungo l'asse verticale\n",
        "        combined = torch.cat((y, preds), dim=2)\n",
        "\n",
        "        # Salvare l'immagine combinata\n",
        "        torchvision.utils.save_image(combined, f\"{folder}/comparison_{idx}.png\")\n",
        "\n",
        "    model.train()  # Ripristina il modello in modalità di addestramento\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def check_accuracy(loader, model, loss_fn, file, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    f1 = 0\n",
        "    val_loss = 0\n",
        "    iteration = 1\n",
        "\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(f'iterations: {len(loader)}')\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            print(f'Iteration number: {iteration}')\n",
        "            iteration += 1\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device).unsqueeze(1)\n",
        "\n",
        "            out = model(x)\n",
        "            val_loss += loss_fn(out, y).item()\n",
        "            preds = torch.sigmoid(out)\n",
        "            preds = (preds > 0.5)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_pixels += torch.numel(preds)\n",
        "            dice_score += (2 * (preds * y).sum()) / ((preds + y).sum() + 1e-8)\n",
        "\n",
        "            # Converti i tensor in numpy array per il calcolo delle metriche\n",
        "            preds_np = preds.cpu().numpy().flatten()\n",
        "            y_np = y.cpu().numpy().flatten()\n",
        "\n",
        "            # Aggiungi le predizioni e le etichette alla lista\n",
        "            all_preds.extend(preds_np)\n",
        "            all_labels.extend(y_np)\n",
        "\n",
        "            precision += precision_score(y_np, preds_np, zero_division=1)\n",
        "            recall += recall_score(y_np, preds_np, zero_division=1)\n",
        "            f1 += f1_score(y_np, preds_np, zero_division=1)\n",
        "\n",
        "    denominator = len(loader)\n",
        "    val_loss /= denominator\n",
        "    accuracy = num_correct / num_pixels * 100\n",
        "    dice = dice_score / denominator\n",
        "    precision_avg = precision / denominator\n",
        "    recall_avg = recall / denominator\n",
        "    f1_avg = f1 / denominator\n",
        "\n",
        "    # Calcola la matrice di confusione\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Dice score: {dice}\")\n",
        "    print(f\"Precision: {precision_avg}\")\n",
        "    print(f\"Recall: {recall_avg}\")\n",
        "    print(f\"F1 Score: {f1_avg}\")\n",
        "    print(f\"Confusion Matrix:\\n {cm}\")\n",
        "    print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
        "\n",
        "    # Salva i risultati su un file di testo\n",
        "    with open(file, \"a\") as f:\n",
        "        f.write(f\"Validation Loss: {val_loss:.4f}\\n\")\n",
        "        f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
        "        f.write(f\"Dice score: {dice}\\n\")\n",
        "        f.write(f\"Precision: {precision_avg}\\n\")\n",
        "        f.write(f\"Recall: {recall_avg}\\n\")\n",
        "        f.write(f\"F1 Score: {f1_avg}\\n\")\n",
        "        f.write(f\"Confusion Matrix:\\n {cm}\\n\")\n",
        "        f.write(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\\n\")\n",
        "        f.write(\"\\n\")  # Riga vuota per separare le epoche\n",
        "\n",
        "    model.train()\n"
      ],
      "metadata": {
        "id": "glwEsWBFHF1r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WORKERS = 4\n",
        "PIN_MEMORY = True\n",
        "IMAGE_HEIGHT = 300\n",
        "IMAGE_WIDTH = 300\n",
        "TEST_IMG_DIR = \"/content/images/test_set\"\n",
        "TEST_MASK_DIR =  \"/content/mask/test_set\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "\n",
        "#trasformazioni\n",
        "test_transform = A.Compose(\n",
        "      [\n",
        "          A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "          A.Normalize(\n",
        "              mean=[0.0,0.0,0.0,0.0],\n",
        "              std=[1.0,1.0,1.0,1.0],\n",
        "          ),\n",
        "          ToTensorV2(),\n",
        "      ],\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    #lista di directory dei modelli\n",
        "    model_paths = [\n",
        "        #\"/content/drive/My Drive/progettoLabAi3/computations/saved/model14/\",\n",
        "        #\"/content/drive/My Drive/progettoLabAi3/computations/saved/model11/\",\n",
        "        #\"/content/drive/My Drive/progettoLabAi3/computations/saved/model4/\",\n",
        "        \"/content/drive/My Drive/progettoLabAi3/computations/saved/model12/\"\n",
        "    ]\n",
        "\n",
        "    models = []\n",
        "\n",
        "    test_ds = MultispectralDataset(\n",
        "            image_dir= TEST_IMG_DIR,\n",
        "            mask_dir= TEST_MASK_DIR,\n",
        "            transform= test_transform,\n",
        "    )\n",
        "\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            num_workers= NUM_WORKERS,\n",
        "            pin_memory=PIN_MEMORY,\n",
        "            shuffle=False,\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for model_path in model_paths:\n",
        "\n",
        "        model = UNET(in_channels=4, out_channels=1).to(DEVICE)\n",
        "        load_checkpoint(torch.load(model_path +\"my_checkpoint.pth.tar\"), model)\n",
        "        models.append(model)\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(0,len(models)):\n",
        "\n",
        "      model = models[i]\n",
        "      model_path = model_paths[i]\n",
        "      print(f\"Sto testando il modello {model_path}\")\n",
        "      check_accuracy(\n",
        "            test_loader,\n",
        "            model,\n",
        "            loss_fn,\n",
        "            file= model_path  +\"outputs/test.txt\",\n",
        "            device=DEVICE\n",
        "      )\n",
        "\n",
        "      save_predictions_as_imgs(\n",
        "              test_loader, model, folder=model_path +\"images_test/\", device=DEVICE\n",
        "      )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtgff3tvKpjT",
        "outputId": "13a11e95-5efd-4743-8af4-d31869709641"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading checkpoint\n",
            "Sto testando il modello /content/drive/My Drive/progettoLabAi3/computations/saved/model12/\n",
            "iterations: 32\n",
            "Iteration number: 1\n",
            "Iteration number: 2\n",
            "Iteration number: 3\n",
            "Iteration number: 4\n",
            "Iteration number: 5\n",
            "Iteration number: 6\n",
            "Iteration number: 7\n",
            "Iteration number: 8\n",
            "Iteration number: 9\n",
            "Iteration number: 10\n",
            "Iteration number: 11\n",
            "Iteration number: 12\n",
            "Iteration number: 13\n",
            "Iteration number: 14\n",
            "Iteration number: 15\n",
            "Iteration number: 16\n",
            "Iteration number: 17\n",
            "Iteration number: 18\n",
            "Iteration number: 19\n",
            "Iteration number: 20\n",
            "Iteration number: 21\n",
            "Iteration number: 22\n",
            "Iteration number: 23\n",
            "Iteration number: 24\n",
            "Iteration number: 25\n",
            "Iteration number: 26\n",
            "Iteration number: 27\n",
            "Iteration number: 28\n",
            "Iteration number: 29\n",
            "Iteration number: 30\n",
            "Iteration number: 31\n",
            "Iteration number: 32\n",
            "Validation Loss: 0.0549\n",
            "Accuracy: 97.80\n",
            "Dice score: 0.8479240536689758\n",
            "Precision: 0.8801447086464811\n",
            "Recall: 0.8181962437589823\n",
            "F1 Score: 0.8479241423044126\n",
            "Confusion Matrix:\n",
            " [[42146109   384280]\n",
            " [  626179  2833432]]\n",
            "TN: 42146109, FP: 384280, FN: 626179, TP: 2833432\n",
            "Saving images to /content/drive/My Drive/progettoLabAi3/computations/saved/model12/images_test/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1\n",
            "Iteration:  2\n",
            "Iteration:  3\n",
            "Iteration:  4\n",
            "Iteration:  5\n",
            "Iteration:  6\n",
            "Iteration:  7\n",
            "Iteration:  8\n",
            "Iteration:  9\n",
            "Iteration:  10\n",
            "Iteration:  11\n",
            "Iteration:  12\n",
            "Iteration:  13\n",
            "Iteration:  14\n",
            "Iteration:  15\n",
            "Iteration:  16\n",
            "Iteration:  17\n",
            "Iteration:  18\n",
            "Iteration:  19\n",
            "Iteration:  20\n",
            "Iteration:  21\n",
            "Iteration:  22\n",
            "Iteration:  23\n",
            "Iteration:  24\n",
            "Iteration:  25\n",
            "Iteration:  26\n",
            "Iteration:  27\n",
            "Iteration:  28\n",
            "Iteration:  29\n",
            "Iteration:  30\n",
            "Iteration:  31\n",
            "Iteration:  32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7LYvLRb1O332"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}